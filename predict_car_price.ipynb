{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEo1yyqh1AO0787p0GBCT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipratiwari/Algorithems/blob/master/predict_car_price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement** - We want to build a machine learning model to predict the price of used cars based on various features such as car model, year of manufacture, mileage, and so on.\n",
        "\n",
        "**Data Source **- We will use the publicly available Used Cars Dataset from Kaggle.\n",
        "\n",
        "**Solution**- We will use Dask to load and preprocess the data in parallel, and Scikit-Learn to build a Random Forest Regression model to predict the price of used cars."
      ],
      "metadata": {
        "id": "TNbHEE_Mh_n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask scikit-learn pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf2FitN7iMGo",
        "outputId": "cc93e1fd-322b-4ee5-a907-cf21bc42cc84"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.9/dist-packages (2022.12.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.9/dist-packages (from dask) (0.12.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from dask) (8.1.3)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.9/dist-packages (from dask) (1.3.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from dask) (2023.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from dask) (6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from dask) (23.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.9/dist-packages (from partd>=0.3.10->dask) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset using Dask"
      ],
      "metadata": {
        "id": "awy9MVTMiigp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "# Download dataset\n",
        "!wget https://www.kaggle.com/austinreese/craigslist-carstrucks-data/download\n",
        "\n",
        "# Load dataset with Dask\n",
        "df = dd.read_csv('download')"
      ],
      "metadata": {
        "id": "ABk_84y4iGrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the dataset"
      ],
      "metadata": {
        "id": "n_Q6L6uZi9ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant columns\n",
        "df = df.drop(columns=['id', 'url', 'region_url', 'image_url', 'description', 'vin', 'county', 'state'])\n",
        "\n",
        "# Convert categorical variables to dummy variables\n",
        "df = dd.get_dummies(df, columns=['manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color'])\n",
        "\n",
        "# Fill missing values with the mean of each column\n",
        "df = df.fillna(df.mean())\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['price']), df['price'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "PiH7YgcGjA4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Scikit-Learn model"
      ],
      "metadata": {
        "id": "6eRqtq1FjFpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "1aD4_ijejI5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using Dask for parallel processing"
      ],
      "metadata": {
        "id": "gGwoRIOpjMiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train.compute(), y_train.compute())"
      ],
      "metadata": {
        "id": "U2Oae5e3jSnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "Ir3rN3mbjMqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred = model.predict(X_test.compute())\n",
        "mse = mean_squared_error(y_test.compute(), y_pred)\n",
        "print(f'Mean Squared Error: {mse:.2f}')"
      ],
      "metadata": {
        "id": "xwx69ZvsjbA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! This example uses Dask to load and preprocess a large dataset of used cars, and Scikit-Learn to build a Random Forest Regression model to predict the price of a used car based on various features such as car model, year of manufacture, mileage, and so on. Note that this dataset is just an example and the model may not be very accurate in practice. Also, the number of trees and other hyperparameters can be tuned to improve the model's performance."
      ],
      "metadata": {
        "id": "GgBgB6fcjMt-"
      }
    }
  ]
}